{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fdavenport/CIVE480A6-climate-change-impacts/blob/main/lectures/06_Analyzing_Extreme_Events.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIVE 480A6: Climate Change Risks and Impacts\n",
        "## Week 9: Analyzing Extreme Events\n",
        "\n",
        "This week's Objectives:\n",
        "1. Analyze the distribution of daily maximum temperature.\n",
        "2. Calculate percentiles of the temperature distribution.\n",
        "3. Calculate how often daily temperatures exceed certain thresholds.\n",
        "4. Calculate \"block maxima\" (in this case, the hottest day of the year).\n",
        "5. Learn how to fit a Generalized Extreme Value (GEV) distribution to the time series of block maxima."
      ],
      "metadata": {
        "id": "KL6cB450IQbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Daily Temperature Data\n",
        "\n",
        "Today we will be looking at daily temperature data. We will again be using data from the [Global Historical climatology Network (GHCN-D)](https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily).  \n",
        "\n",
        "We will be looking specifically at data from a weather station near Atlanta, Georgia. The data file contains the high and low (maximum and minimum) temperatures for each day.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/fdavenport/CIVE480A6-climate-change-impacts/main/lectures/img/atlanta_map.png\" width=\"400\">\n",
        "<img src=\"https://raw.githubusercontent.com/fdavenport/CIVE480A6-climate-change-impacts/main/lectures/img/heatwave.jpg\" width=\"300\">"
      ],
      "metadata": {
        "id": "A7uC6PcAJG8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data has already been added to the course github page at the following link:\n",
        "\n",
        "atl_temp_data_url = \"https://raw.githubusercontent.com/fdavenport/CIVE480A6-climate-change-impacts/refs/heads/main/lectures/data/USW00013874_atlanta_temp.csv\"\n"
      ],
      "metadata": {
        "id": "RxwV1FRsJNZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we are working with tabular data in a .csv file, so we need to import the pandas library\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "78Nkc2J49f-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the data\n",
        "\n",
        "atl_data = pd.read_csv(atl_temp_data_url)"
      ],
      "metadata": {
        "id": "qjUMWJ9r9fkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the data\n",
        "\n",
        "atl_data"
      ],
      "metadata": {
        "id": "SKjRZFUknw5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the table contains daily data beginning in 1940 and ended in 2022. There are two variable columns that correspond to the high (max) and low (min) temperature on each day."
      ],
      "metadata": {
        "id": "lpAmGCnDUNlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert DATE column to datetime format so that we can add year and month information\n",
        "\n",
        "atl_data[\"DATE\"] = pd.to_datetime(atl_data[\"DATE\"])\n",
        "atl_data[\"year\"] = atl_data[\"DATE\"].dt.year\n",
        "atl_data[\"month\"] = atl_data[\"DATE\"].dt.month\n",
        "\n",
        "atl_data.set_index(\"DATE\", inplace=True)\n",
        "\n",
        "atl_data\n"
      ],
      "metadata": {
        "id": "s9k_JPAmnC-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a summary of the data\n",
        "\n",
        "\n",
        "atl_data.describe()"
      ],
      "metadata": {
        "id": "r24JdZFgJ3wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot to make graphs\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "gWBCxTR1L4R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a plot of the data\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.scatter(x = atl_data.index, y = atl_data[\"TMAX_degC\"], s = 1, color = \"brown\")\n",
        "ax.set_title(\"Daily Maximum Temperature in Atlanta, GA\")\n",
        "ax.set_ylabel(\"Temperature(C)\");\n",
        "\n"
      ],
      "metadata": {
        "id": "_CS2igS0FsEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that there is a large spread in daily maximum temperature in Atlanta, with daily high temperatures ranging anywhere from -10C on the coldest days to 40C on the very hottest days.\n",
        "\n",
        "It's hard to tell whether there are trends in the data, but it does appear that there haven't been as many extremely cold days since ~2000."
      ],
      "metadata": {
        "id": "OuAWr1MIUgkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a histogram of the daily temperature data\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize = (15, 5))\n",
        "\n",
        "\n",
        "axes[0].hist(x = atl_data[\"TMAX_degC\"], bins = 30, color = \"brown\", edgecolor = \"gray\");\n",
        "axes[0].set_title(\"Distribution of daily maximum T\")\n",
        "axes[0].set_xlabel(\"Temperature (C)\")\n",
        "axes[0].set_ylabel(\"number of days\");\n",
        "\n",
        "axes[1].hist(x = atl_data[\"TMIN_degC\"], bins = 30, color = \"tomato\", edgecolor = \"gray\");\n",
        "axes[1].set_title(\"Distribution of daily minimum T\")\n",
        "axes[1].set_xlabel(\"Temperature (C)\")\n",
        "axes[1].set_ylabel(\"number of days\");"
      ],
      "metadata": {
        "id": "phaOqsnlFr-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Calculating percentiles and exceedences\n",
        "\n",
        "In this section, we are going to look at the 95th percentile minimum and maximum temperature within the summer months (June, July, and August) in Atlanta, GA. This will give us a sense for what a rare or \"extreme\" hot temperature would look like at this particular location.\n",
        "\n",
        "Oftentimes, we use percentiles to define extremes, because what is extreme in one place might not be extreme in another location. For example, 100 F is very extreme in Alaska, but not so extreme in Phoenix, AZ.\n",
        "\n",
        "First let's look at daily maximum summer temperatures in Atlanta:"
      ],
      "metadata": {
        "id": "dmb4fDNwZjVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## subset the data for summer months\n",
        "\n",
        "summer_data = atl_data.loc[atl_data[\"month\"].isin([6, 7, 8])]\n",
        "\n",
        "summer_data\n"
      ],
      "metadata": {
        "id": "J26cHMInZio8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the [quantile()](https://numpy.org/doc/2.0/reference/generated/numpy.quantile.html) function from the numpy package to calculate the 95th percentile"
      ],
      "metadata": {
        "id": "JpJGYls-U4oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy\n",
        "\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "W0zRSXWnYMMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the np.quantile function,\n",
        "# the first argument is our data, the second argument is the quantile (aka percentile) that we want to calculate\n",
        "\n",
        "# calculate the 95th percentile of TMAX for all summer days:\n",
        "\n",
        "TMAX_p95 = np.quantile(summer_data[\"TMAX_degC\"], q = 0.95)\n",
        "\n",
        "TMAX_p95"
      ],
      "metadata": {
        "id": "GYIw5hE86DOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## conver to Fahrenheit\n",
        "\n",
        "TMAX_p95*9/5+32"
      ],
      "metadata": {
        "id": "O0QYKu7x6NCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tells us that about 5% of summer days in Atlanta have temperatures above 96.08 F."
      ],
      "metadata": {
        "id": "GqxhgHviV2Tw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many days have maximum temperatures above the 95th percentile? To answer this, we will compare the temperature on each day to our 95th percentile threshold to see if the value is greater than or equal to the threshold. We will first do this for the first 10 values from our table to see how this works:  "
      ],
      "metadata": {
        "id": "zQ0Zi7qbxU91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print out the first 10 rows of our table\n",
        "\n",
        "summer_data.iloc[0:10]"
      ],
      "metadata": {
        "id": "gWGDeDHQ7TpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## compare these 10 values for\n",
        "summer_data.iloc[1:10][\"TMAX_degC\"] >= TMAX_p95"
      ],
      "metadata": {
        "id": "jP2eYcoIWhcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python returns \"False\" if the temperature is lower than TMAX_p95, and \"True\" if the temperature is greater than TMAX_p95.\n",
        "\n",
        "Conveniently, Python equates \"True\" with a value of 1, and \"False\" with a value of 0. If we take the sum of the True and False data, the total sum will be equal to the number of True cases."
      ],
      "metadata": {
        "id": "1Ac-nVClW0O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(summer_data.iloc[1:10][\"TMAX_degC\"] >= TMAX_p95)"
      ],
      "metadata": {
        "id": "i-M4UwjW7SPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tells us that there were two True cases within the first 10 rows. If we repeat this for all of the summer data, we will know the total number of days with temperatures greater than or equal to TMAX_p95:"
      ],
      "metadata": {
        "id": "jRbnSG3yXOKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(summer_data[\"TMAX_degC\"] >= TMAX_p95)\n"
      ],
      "metadata": {
        "id": "t-ay1jZUxSgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 456 days with temperatures >= 35.6 C."
      ],
      "metadata": {
        "id": "uq7k2d6iXfqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## get the total number of rows (aka days) in our data\n",
        "\n",
        "len(summer_data)"
      ],
      "metadata": {
        "id": "Dexzfcxz7xdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## calculate percentage of days with T > TMAX_p95\n",
        "\n",
        "456/7636*100"
      ],
      "metadata": {
        "id": "8w6jBrTw73DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.97% of days have temperatures above TMAX_p95. This isn't exactly 5% because it turns out there are a lot of duplicate values in the data. Quite a few days have temperatures of exactly 35.6 C.\n",
        "\n",
        "We can use the same function to calculate different percentiles:"
      ],
      "metadata": {
        "id": "f8JMfRLLXt6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the 99th percentile of maximum daily temperature\n",
        "np.quantile(summer_data[\"TMAX_degC\"], q = 0.99)"
      ],
      "metadata": {
        "id": "hxygXT3n82UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to Fahrenheit\n",
        "\n",
        "37.2*9/5+32"
      ],
      "metadata": {
        "id": "neNynHx382E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the 1st percentile of minimum daily summer temperature\n",
        "# in other words, only 1% of summer days have temperatures below this value\n",
        "\n",
        "np.quantile(summer_data[\"TMIN_degC\"], q = 0.01)"
      ],
      "metadata": {
        "id": "9Nlx-OLp9Gqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to F\n",
        "\n",
        "13.9*9/5+32"
      ],
      "metadata": {
        "id": "wC9gfiDt9QRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Calculating changes in the frequency of extreme cold and extreme hot days"
      ],
      "metadata": {
        "id": "xiCsns-uY1bI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's calculate the frequency of extreme hot days over time to see if it has changed. We will look at summertime TMAX and TMIN.\n",
        "\n",
        "While TMAX tells us the hottest conditions of the day, daily minimum temperatures (TMIN) are an especially important metric to understand the human health consequences of heat waves. If it stays very warm at night, people are unable to cool down, and sustained hot temperatures become more likely to cause negative health impacts."
      ],
      "metadata": {
        "id": "wfhspWsZyALn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TMIN_p95 = np.quantile(summer_data[\"TMIN_degC\"], q=0.95)\n"
      ],
      "metadata": {
        "id": "1YTF-lsNYxsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## how many days are there with maximum temperatures above the 95th percentile in each year?\n",
        "## Hint: let's use our code from previous lectures to loop through all of the years\n",
        "\n",
        "annual_freq = pd.DataFrame(columns = [\"year\", \"days_above_TMAX_p95\", \"days_above_TMIN_p95\"], index = range(83))\n",
        "\n",
        "for i, yr in enumerate(range(1940, 2023)):\n",
        "  data_yr = summer_data[str(yr):str(yr)] # create a subset with summer data for the current year\n",
        "\n",
        "  annual_freq.loc[i, \"year\"] = yr\n",
        "\n",
        "  # check how many days exceeded the 95th percentile\n",
        "  annual_freq.loc[i, \"days_above_TMAX_p95\"] = sum(data_yr[\"TMAX_degC\"] >= TMAX_p95)\n",
        "  annual_freq.loc[i, \"days_above_TMIN_p95\"] = sum(data_yr[\"TMIN_degC\"] >= TMIN_p95)\n"
      ],
      "metadata": {
        "id": "P9IfSuaEYMCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## check the results\n",
        "\n",
        "annual_freq"
      ],
      "metadata": {
        "id": "rZyj1rvYUhr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## make a time series plot of the change in TMAX and TMIN days above the 95th percentile:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X5kfAWG3t8n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are some other ways we could assess changes in the intensity or frequency of extreme hot events?\n",
        "\n",
        "\n",
        "*   ?\n",
        "*   ?\n",
        "\n"
      ],
      "metadata": {
        "id": "k_39F22RV43e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Using Extreme Value statistics to analyze very rare temperature events\n",
        "\n",
        "In this section, we will use extreme value statistics to estimate the probability of very rare extreme events, including those that may be more rare than anything in the historical data."
      ],
      "metadata": {
        "id": "vZ3LbcuEYNZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall from class, that extreme value theory applies to \"block maxima\", or the maximum value in each block of time. For this case, we will consider each calendar year as a block of time. This means we need to calculate the maximum value within each year. For this analysis, we will look at TMAX."
      ],
      "metadata": {
        "id": "8J82gQDN1vq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## calculate annual maximum TMAX value\n",
        "\n",
        "annual_max = pd.DataFrame(columns = [\"year\", \"TMAX_max\"], index = range(83))\n",
        "\n",
        "for i, yr in enumerate(range(1940, 2023)):\n",
        "  data_yr = summer_data[str(yr):str(yr)] # create a subset with summer data for the current year\n",
        "\n",
        "  annual_max.loc[i, \"year\"] = yr\n",
        "  annual_max.loc[i, \"TMAX_max\"] = data_yr[\"TMAX_degC\"].max()\n",
        "\n",
        "annual_max[\"TMAX_max\"] = annual_max[\"TMAX_max\"].astype(\"float\")"
      ],
      "metadata": {
        "id": "hRrxV-BbVgZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## plot annual maximum time series to see\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(annual_max[\"year\"], annual_max[\"TMAX_max\"], color = \"gray\")\n",
        "ax.scatter(annual_max[\"year\"], annual_max[\"TMAX_max\"], color = \"purple\", zorder = 5)\n",
        "ax.set_title(\"Time series of annual maxima\")\n",
        "ax.set_ylabel(\"Maximum Temperature in each year(C)\");"
      ],
      "metadata": {
        "id": "zRQeVnjZV0Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## plot histogram of annual maxima\n",
        "\n"
      ],
      "metadata": {
        "id": "-72oP4t0byfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Fisher–Tippett–Gnedenko theorem tells us that the distribution of block maxima can be described by the Generalized Extreme Value (GEV) distribution.\n",
        "\n",
        "The GEV distribution is described by three parameters: the location ($\\mu$), the scale ($\\sigma$), and the shape ($\\xi$).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/fdavenport/CIVE480A6-climate-change-impacts/main/lectures/img/GEV.png\" width=\"500\">"
      ],
      "metadata": {
        "id": "sqkKlZUw6Su8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like we can calculate mean and standard deviation for a sample dataset, we can figure out the location, scale, and shape parameters that best match our data.\n",
        "\n",
        "We will use the [genextreme()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.genextreme.html#scipy.stats.genextreme) function from the scipy package to calculate the GEV parameters for our data.  "
      ],
      "metadata": {
        "id": "XAFs6sK67Ajw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## import genextreme() function\n",
        "\n"
      ],
      "metadata": {
        "id": "xkkdvhNjPtge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## fit our data\n",
        "\n"
      ],
      "metadata": {
        "id": "A-mt3G7C1qGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## make a graph of a GEV distribution with these parameters\n",
        "\n"
      ],
      "metadata": {
        "id": "g4_FefJ115jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## plot the histogram of our data and the GEV distribution together\n",
        "\n"
      ],
      "metadata": {
        "id": "UxRZdRmxng60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have calculated the parameters of the GEV distribution, we can calculate the magnitude of events with specific return periods (or in other words, an event with a specific probability, such as 1%)."
      ],
      "metadata": {
        "id": "IAyQbKvZnnJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## what is the magnitude of a 10-year event?\n",
        "\n"
      ],
      "metadata": {
        "id": "AcYG3ZLT8Jnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## what about a 20-year event? a 100-year event? a 500-year event?\n",
        "\n"
      ],
      "metadata": {
        "id": "GT1lDqxWfYwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make a figure showing how the event magnitude changes for different return periods:"
      ],
      "metadata": {
        "id": "5SsofTyDrK3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## define return periods\n",
        "\n",
        "return_periods = np.array([1.01, 1.02, 1.05, 1.1, 1.5, 2, 5, 10, 20, 30, 40, 50, 100, 200, 500, 1000])"
      ],
      "metadata": {
        "id": "tDYbL8HdrRg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## calculate magnitude for each return period\n"
      ],
      "metadata": {
        "id": "Y3xubDLyrWMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## make a figure showing return periods\n",
        "\n",
        "\n",
        "\n",
        "#import matplotlib.ticker as mticker\n",
        "#ax.xaxis.set_major_formatter(mticker.ScalarFormatter())\n",
        "#ax.ticklabel_format(style='plain', axis='x')\n"
      ],
      "metadata": {
        "id": "TMpwqQYb8iXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add our data points to the plot to see how closely they match the curve. To do this, we need to calculate the *empirical* return level of each data point. The empirical return level refers to how frequently different values in our data were exceeded within the period of record.\n",
        "\n",
        "For example, if we have 84 years of data, the most extreme event in our data has an empirical return period of 84 years because it only occurred once in 84 years. The second most extreme event has an empirical return level of 42 years because it was exceeded twice in 84 years.\n"
      ],
      "metadata": {
        "id": "gqGfuQclmqsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## The function below will calculate empirical return periods for a timeseries of annual maxima\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "def calc_empirical_return_level(data):\n",
        "    \"\"\"\n",
        "    Compute empirical return level\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(index=np.arange(data.size))\n",
        "    # sort the data\n",
        "    df[\"sorted_value\"] = np.sort(data)[::-1]\n",
        "    # rank via scipy instead to deal with duplicate values\n",
        "    df[\"ranked_value\"] = np.sort(stats.rankdata(-data))\n",
        "    # find exceedence probability\n",
        "    n = data.size\n",
        "    df[\"exceedance\"] = df[\"ranked_value\"] / (n + 1)\n",
        "    # find return period\n",
        "    df[\"return_period\"] = 1 / df[\"exceedance\"]\n",
        "\n",
        "    df = df[::-1]\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "ggC4AFlPivTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## calculate empirical return levels for our data\n",
        "\n"
      ],
      "metadata": {
        "id": "ukhWWbJrjBaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In class, we have talked about how extreme events are changing. This means that a 100-year event now might become a 50-year event in the future!\n",
        "How might we address this if we are trying to analyze extreme event risk within a particular engineering application?  \n",
        "\n",
        "\n",
        "*   ?\n",
        "*   ?\n",
        "*  ?\n",
        "\n"
      ],
      "metadata": {
        "id": "dWX72yQUrqx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practice:\n",
        "\n",
        "Practice applying your extreme value analysis to calculate the 100-year flood for the [Merced River](https://waterdata.usgs.gov/nwis/inventory/?site_no=11266500) in Yosemite National Park in California. The USGS provides annual peak data for each of it's streamgages, and the data for this location has been added to the github site at the following url:"
      ],
      "metadata": {
        "id": "nQcpJoDlqHRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merced_river_annual_peaks_url = \"https://raw.githubusercontent.com/fdavenport/CIVE480A6-climate-change-impacts/refs/heads/main/lectures/data/USGS_11266500_peak_flows.csv\""
      ],
      "metadata": {
        "id": "1cnQnutWYSkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## read in the data\n",
        "\n"
      ],
      "metadata": {
        "id": "HFtzULDlqz_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## plot a time series of the annual_maxima to check the data\n",
        "\n"
      ],
      "metadata": {
        "id": "MFKUUnxjuj9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## calculate the GEV parameters\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wBtfRHwAunsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## make a plot of the GEV distribution\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eCk8nubSuqB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## make a plot of event magnitude vs. return period\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g4-PbTH3uulq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}